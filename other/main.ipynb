{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Hubzu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Hubzu.csv')\n",
    "\n",
    "df = df.dropna(subset=['Address', 'Date']) #drop null values from Address & Date\n",
    "\n",
    "#Splits date to date & time\n",
    "df.Date = df.Date.str.replace('at', ',')\n",
    "df[['Date', 'Time']] = df['Date'].str.split(',', n=1, expand=True)\n",
    "df.Time = df.Time.str.replace('local', '')\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df = df.dropna(subset=['Date'])\n",
    "\n",
    "#Keeps valid date range\n",
    "start_date = pd.to_datetime('2025-07-02')\n",
    "end_date = pd.to_datetime('2025-08-02')\n",
    "df = df[df['Date'] >= start_date]\n",
    "df = df[df['Date'] <= end_date]\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "#Splits address2 to city, state * postal\n",
    "df[['City', 'Text2']] = df['Address2'].str.split(',', n=1, expand=True)\n",
    "df[['Blank', 'State', 'Postal']] = df['Text2'].str.split('  ', n=2, expand=True)\n",
    "df = df.drop(['Address2','Text2' , 'Blank'], axis=1)\n",
    "\n",
    "#Drops address in case column\n",
    "keywords = ['ST', 'WY', 'DR']\n",
    "pattern = '|'.join(keywords)\n",
    "df.Case = df.Case.str.upper()\n",
    "df['Case'] = df['Case'].where(~df['Case'].isin(df['Address']), '')\n",
    "df['Case'] = df['Case'].where(~df['Case'].str.contains(pattern, case=False, na=False), '')\n",
    "\n",
    "df = df.drop_duplicates(subset=['Address']) #Removes duplicate address\n",
    "\n",
    "#Create the clean csv with correct column order\n",
    "cols = ['Address', 'City', 'State', 'Postal', 'County', 'Date', 'Time', 'Case', 'URL', 'Source', 'Atty', 'Atty_Contact']\n",
    "df = df.reindex(columns=cols)\n",
    "df.to_csv('Hubzu2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Xome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Xome.csv')\n",
    "\n",
    "#Creates the county column\n",
    "county_cols = ['Text', 'Text1', 'Text2', 'Text3', 'Text4', 'Text5', 'Text6', 'Text7', 'Text8', 'Text9']\n",
    "df['County'] = df.apply(lambda row: next((str(row[col]) for col in county_cols if 'County' in str(row[col])), None), axis=1)\n",
    "df = df.drop(['Text', 'Text1', 'Text2', 'Text3', 'Text4', 'Text5', 'Text6', 'Text7', 'Text8', 'Text9'], axis=1)\n",
    "df['County'] = df['County'].str.replace(r'\\s+', '', regex=True) #removes newlines and whitespaces\n",
    "df['County'] = df['County'].str.replace('MunicipalityCounty:', '')\n",
    "\n",
    "#Splits address2 to city, state and postal\n",
    "df['City'] = df['Address2'].str.rsplit(\" \", n=2).str[0]\n",
    "df['State'] = df['Address2'].str.split(\" \").str[-2]\n",
    "df['Postal'] = df['Address2'].str.split(\" \").str[-1]\n",
    "df = df.drop(['Address2'], axis=1)\n",
    "\n",
    "#Splits date into date & time\n",
    "df = df.dropna(subset='Date')\n",
    "df['Date'] = df['Date'].str.replace(r'\\s+', '', regex=True) #removes newlines and whitespaces\n",
    "df[['Date', 'Extra']] = df['Date'].str.split('-', expand=True)\n",
    "df = df.drop(['Extra'], axis=1)\n",
    "df[['Date', 'Time']] = df['Date'].str.split(',', expand=True)\n",
    "\n",
    "#Parses date into correct format and filters within date range\n",
    "start_date = pd.to_datetime('2025-07-02')\n",
    "end_date = pd.to_datetime('2025-08-02')\n",
    "df['date_fixed'] = df['Date'].str.replace(r'([a-zA-Z]+)(\\d+)', r'\\1 \\2', regex=True)\n",
    "df['date_with_year'] = df['date_fixed'] + ' 2025'\n",
    "df['Date'] = pd.to_datetime(df['date_with_year'], format='%B %d %Y', errors='coerce')\n",
    "df = df[df['Date'] >= start_date]\n",
    "df = df[df['Date'] <= end_date]\n",
    "df = df.sort_values(by='Date')\n",
    "df = df.drop(['date_fixed', 'date_with_year'], axis=1)\n",
    "\n",
    "df = df.drop_duplicates(subset=['Address']) #Removes duplicate address\n",
    "\n",
    "#Creates clean csv with proper column order\n",
    "cols = ['Address', 'City', 'State', 'Postal', 'County', 'Date', 'Time', 'Case', 'URL', 'Source', 'Atty', 'Atty_Contact']\n",
    "df = df.reindex(columns=cols)\n",
    "df.to_csv('Xome2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Realforeclose\n",
    "### Pre-clean the Details column in Excel prior to using pandas.\n",
    "- Remove blank dates.\n",
    "- Clean judgment and parcel columns.\n",
    "- Remove row without address.\n",
    "- Clean address2 column.\n",
    "- Clean value column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('RFC.csv')\n",
    "\n",
    "#Splits date into date & time\n",
    "df['Date'] = df['Date'].str.replace('\\n', '')\n",
    "df['Date'] = df['Date'].str.replace('Auction Starts', '')\n",
    "df[['Date', 'Time']] = df['Date'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "#Filters judgment value above 20K\n",
    "df['Judgment'] = df['Judgment'].str.replace('$', '')\n",
    "df['Judgment'] = df['Judgment'].str.replace(',', '')\n",
    "df['Judgment'] = pd.to_numeric(df['Judgment'], errors='coerce')\n",
    "df = df[(df['Judgment'].isna()) | (df['Judgment'] >= 20000)]\n",
    "\n",
    "#Removes rows with Timeshare and retain rows with Address\n",
    "#Splits Address2 into city, state and postal\n",
    "df = df[~df['Parcel'].str.contains('TIMESHARE', case=False, na=False)]\n",
    "df[['City', 'Postal']] = df['Address2'].str.split(',', expand=True)\n",
    "df['Postal'] = df['Postal'].str.replace('NO ZIP', '')\n",
    "\n",
    "#Filters values >= 100K but <= 700K\n",
    "df['Value'] = df['Value'].str.replace('$', '')\n",
    "df['Value'] = df['Value'].str.replace(',', '')\n",
    "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "df = df[(df['Value'].isna()) | (df['Value'] >= 100000)]\n",
    "df = df[(df['Value'].isna()) | (df['Value'] <= 700000)]\n",
    "\n",
    "#Identifies the states\n",
    "df.loc[df['Postal'].str.contains('CO', case=False, na=False), 'State'] = 'CO'\n",
    "df.loc[df['Postal'].str.contains('FL', case=False, na=False), 'State'] = 'FL'\n",
    "df.loc[df['URL'].str.contains('ohio', case=False, na=False), 'State'] = 'OH'\n",
    "df.loc[df['URL'].str.contains('pa.', case=False, na=False), 'State'] = 'PA'\n",
    "df['State'] = df['State'].fillna('FL')\n",
    "df['County'] = df['URL'].str.extract(r'//([^\\.]+)')\n",
    "df['Postal'] = df['Postal'].str.replace('CO-', '')\n",
    "df['Postal'] = df['Postal'].str.replace('FL-', '')\n",
    "\n",
    "df = df.drop_duplicates(subset=['Address']) #Removes duplicate address\n",
    "\n",
    "#Creates clean csv with proper column order\n",
    "cols = ['Address', 'City', 'State', 'Postal', 'County', 'Date', 'Time', 'Case', 'URL', 'Source', 'Atty', 'Atty_Contact']\n",
    "df = df.reindex(columns=cols)\n",
    "df.to_csv('RFC2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Auction\n",
    "- Pre-clean the Atty column.\n",
    "- Post-clean the city, state, and county columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/lostinthecode/RegMichel/input/Auction.csv', encoding=\"latin-1\")\n",
    "\n",
    "# Creates city, state, and postal columns\n",
    "df['Address3'] = df['Address2'].str.replace(r',,+', ',', regex=True)\n",
    "df['City'] = df['Address3'].str.split(',').str[-3]\n",
    "df['StateZip'] = df['Address3'].str.split(',').str[-2].str.strip()\n",
    "df[['State', 'Postal']] = df['StateZip'].str.split(' ', expand=True)\n",
    "df['County'] = df['Address3'].str.split(',').str[-1]\n",
    "df['City'] = df['City'].str.replace(r'\\s*\\(.*', '', regex=True)\n",
    "\n",
    "# Creates atty_contact column\n",
    "df['Atty_Contact'] = df['Atty_Contact'].str.split('call', n=1).str[1].str.strip()\n",
    "\n",
    "# Removes unnecessary keywords from address\n",
    "df['Address'] = df['Address'].str.replace(' aka ', ',', case=False)\n",
    "df['Address'] = df['Address'].str.replace(' a/k/a ', ',', case=False)\n",
    "df['Address'] = df['Address'].str.replace(' fka ', ',', case=False)\n",
    "df['Address'] = df['Address'].str.replace(' f/k/a ', ',', case=False)\n",
    "df['Address'] = df['Address'].str.replace(' nka ', ',', case=False)\n",
    "df['Address'] = df['Address'].str.replace(' n/k/a ', ',', case=False)\n",
    "df['Address'] = df['Address'].str.replace(' arta ', ',', case=False)\n",
    "df[['Address', 'Extra2']] = df['Address'].str.split(',', n=1, expand=True)\n",
    "\n",
    "# Filters value >= 100K and <= 700K\n",
    "df['Value'] = df['Value'].str.replace('$', '')\n",
    "df['Value'] = df['Value'].str.replace(',', '')\n",
    "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "df = df[(df['Value'].isna()) | (df['Value'] >= 100000)]\n",
    "df = df[(df['Value'].isna()) | (df['Value'] <= 700000)]\n",
    "\n",
    "# Transforms date and time into their proper format\n",
    "df['Date'] = df['Date'].str.split('\\n').str[0]\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Date'] = df['Date'].fillna(df['Date2'])\n",
    "\n",
    "df['Time2'] = df['Time2'].str.split('-').str[0]\n",
    "df['Time'] = df['Time'].str.replace('TBD', '', regex=True)\n",
    "df['Time'] = df['Time'].fillna(df['Time2'])\n",
    "\n",
    "# # Keeps valid date range\n",
    "df = df.dropna(subset='Date')\n",
    "start_date = pd.to_datetime('2025-07-02')\n",
    "end_date = pd.to_datetime('2025-08-02')\n",
    "df = df[df['Date'] >= start_date]\n",
    "df = df[df['Date'] <= end_date]\n",
    "\n",
    "# Creates clean csv with proper column order\n",
    "cols = ['Address', 'City', 'State', 'Postal', 'County', 'Date', 'Time', 'Case', 'URL', 'Source', 'Atty', 'Atty_Contact']\n",
    "df = df.reindex(columns=cols)\n",
    "df.to_csv('Auction2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Masterlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "files = ['RFC2.csv', 'Xome2.csv', 'Auction2.csv', 'Hubzu2.csv']\n",
    "df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "\n",
    "#Convert to title case\n",
    "df.Address = df.Address.str.title()\n",
    "df.City = df.City.str.title()\n",
    "df.County = df.County.str.title()\n",
    "df.Atty = df.Atty.str.title()\n",
    "\n",
    "#Limit postal code to first 5 digits\n",
    "df['Postal'] = df['Postal'].astype(str)\n",
    "df.Postal = df.Postal.str[:5]\n",
    "\n",
    "#Replace/remove symbols\n",
    "df.Address = df.Address.str.replace('.', '')\n",
    "df.Address = df.Address.str.replace(',', '')\n",
    "df.Address = df.Address.str.replace('#', '')\n",
    "df.Address = df.Address.str.replace('& ', '')\n",
    "df.Address = df.Address.str.replace('-', ' ')\n",
    "\n",
    "#Abbreviate\n",
    "df.Address = df.Address.str.replace('Street', 'St')\n",
    "df.Address = df.Address.str.replace('Drive', 'Dr')\n",
    "df.Address = df.Address.str.replace('Road', 'Rd')\n",
    "df.Address = df.Address.str.replace('Lane', 'Ln')\n",
    "df.Address = df.Address.str.replace('Avenue', 'Ave')\n",
    "df.Address = df.Address.str.replace('Terrace', 'Ter')\n",
    "df.Address = df.Address.str.replace('Circle', 'Cir')\n",
    "df.Address = df.Address.str.replace('Court', 'Ct')\n",
    "df.Address = df.Address.str.replace('Place', 'Pl')\n",
    "df.Address = df.Address.str.replace('Boulevard', 'Blvd')\n",
    "df.Address = df.Address.str.replace('Parkway', 'Pkwy')\n",
    "df.Address = df.Address.str.replace('Ridge', 'Rdg')\n",
    "df.Address = df.Address.str.replace('Trail', 'Trl')\n",
    "df.Address = df.Address.str.replace('North', 'N')\n",
    "df.Address = df.Address.str.replace('Northeast', 'NE')\n",
    "df.Address = df.Address.str.replace('Northwest', 'NW')\n",
    "df.Address = df.Address.str.replace('South', 'S')\n",
    "df.Address = df.Address.str.replace('Southeast', 'SE')\n",
    "df.Address = df.Address.str.replace('Southwest', 'SW')\n",
    "df.Address = df.Address.str.replace('East', 'E')\n",
    "df.Address = df.Address.str.replace('West', 'W')\n",
    "\n",
    "#Capitalize common terms in Atty column\n",
    "df.Atty = df.Atty.str.replace('Llc', 'LLC')\n",
    "df.Atty = df.Atty.str.replace('llc', 'LLC')\n",
    "df.Atty = df.Atty.str.replace('Llp', 'LLP')\n",
    "df.Atty = df.Atty.str.replace('Pc', 'PC')\n",
    "\n",
    "#Clean County column\n",
    "df.County = df.County.str.replace('Myorangeclerk', 'My Orange Clerk')\n",
    "df.County = df.County.str.replace('County', '')\n",
    "\n",
    "#Removes duplicates in Address but fill null values with values of duplicate rows prior to dropping\n",
    "df = df.groupby('Address', as_index=False).first()\n",
    "\n",
    "# #Create new clean csv\n",
    "df.to_csv('Clean_062825.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# DealMachine - Inactive, this is for update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "df = pd.read_csv(\"DM_081824.csv\")\n",
    "\n",
    "\n",
    "df = df.drop(['contact_id', 'lead_id', 'associated_property_id', 'associated_property_address_full', \n",
    "              'associated_property_address_line_2', 'associated_parcel_id', 'primary_mailing_address',\n",
    "              'primary_mailing_city', 'primary_mailing_state', 'primary_mailing_zip',\n",
    "              'contact_flags', 'mailing_address_previous', 'mailing_address_zip_previous',\n",
    "              'mailing_address_city_previous', 'mailing_address_state_previous', 'gender',\n",
    "              'mob', 'language_preference', 'marital_status', 'est_household_income_code', 'home_business', 'net_asset_value',\n",
    "              'education_model', 'occupation_group', 'occupation_code', 'business_owner',\n",
    "              'phone_1_activity_status', 'phone_1_carrier', 'phone_1_prepaid_indicator',\n",
    "              'phone_1_usage_2_months', 'phone_1_usage_12_months', 'phone_2_activity_status', \n",
    "              'phone_2_carrier', 'phone_2_prepaid_indicator', 'phone_2_usage_2_months', \n",
    "              'phone_2_usage_12_months', 'phone_3_activity_status_code', 'phone_3_owner',\n",
    "              'phone_3_prepaid_indicator', 'phone_3_usage_2_months', 'phone_3_usage_12_months'], axis=1)\n",
    "\n",
    "df.rename(columns={'associated_property_address_line_1': 'Address', 'associated_property_address_city': 'City',\n",
    "                   'associated_property_address_state': 'State', 'associated_property_address_zipcode': 'Postal Code',\n",
    "                   'first_name': 'First Name', 'last_name': 'Last Name', 'middle_initial': 'Middle Name',\n",
    "                   'generational_suffix': 'Suffix Name', 'email_address_1': 'Email',\n",
    "                   'email_address_2': 'Email - 2', 'email_address_3': 'Email - 3', \n",
    "                   'phone_1': 'Phone', 'phone_1_type': 'Phone Type', 'phone_2': 'Phone No. 2',\n",
    "                   'phone_2_type': 'Phone Type (2)', 'phone_3': 'Phone No. 3', \n",
    "                   'phone_3_type': 'Phone Type (3)'}, inplace=True)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "df.Email = df.Email.str.lower()\n",
    "df['Email - 2'] = df['Email - 2'].str.lower()\n",
    "df['Email - 3'] = df['Email - 3'].str.lower()\n",
    "\n",
    "df['Phone Type'] = df['Phone Type'].str.replace('Wireless', 'Mobile')\n",
    "df['Phone Type (2)'] = df['Phone Type (2)'].str.replace('Wireless', 'Mobile')\n",
    "df['Phone Type (3)'] = df['Phone Type (3)'].str.replace('Wireless', 'Mobile')\n",
    "\n",
    "df['Phone'] = df['Phone'].replace({'DNC Excluded': '', 'DNC Excluded, Landline Excluded': '', ', Landline Excluded': '', 'Landline Excluded': ''}, regex=True).replace('', np.nan)\n",
    "df['Phone No. 2'] = df['Phone No. 2'].replace({'DNC Excluded': '', 'DNC Excluded, Landline Excluded': '', ', Landline Excluded': '', 'Landline Excluded': ''}, regex=True).replace('', np.nan)\n",
    "df['Phone No. 3'] = df['Phone No. 3'].replace({'DNC Excluded': '', 'DNC Excluded, Landline Excluded': '', ', Landline Excluded': '', 'Landline Excluded': ''}, regex=True).replace('', np.nan)\n",
    "\n",
    "df['Phone'] = df['Phone'].combine_first(df['Phone No. 2'])\n",
    "df['Phone Type'] = df['Phone Type'].combine_first(df['Phone Type (2)'])\n",
    "\n",
    "df['Phone No. 2'] = df.apply(lambda row: row['Phone No. 2'].replace(float(row['Phone']), ''), axis=1)\n",
    "\n",
    "# df['Phone No. 2'] = df['Phone No. 2'].combine_first(df['Phone No. 3'])\n",
    "# df['Phone Type (2)'] = df['Phone Type (2)'].combine_first(df['Phone Type (3)'])\n",
    "\n",
    "df['Phone No. 2'] = df['Phone No. 2'].where(~df['Phone'])\n",
    "df = df.sort_values('Phone', ascending=False, na_position='last')\n",
    "\n",
    "df.to_csv('clean_DM_081824.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
